{"title":"Hadoop考试","uid":"5aa55648d7b2f24c13a30d9efcc0b1bf","slug":"temp_Hadoop","date":"2022-12-04T05:07:37.197Z","updated":"2023-01-10T01:10:19.437Z","comments":true,"path":"api/articles/temp_Hadoop.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/FHangH/FHangBlogCDN_03@master/Aurora_ (107).webp","content":"<h1 id=\"Hadoop集群2022-11-11\"><a href=\"#Hadoop集群2022-11-11\" class=\"headerlink\" title=\"Hadoop集群2022.11.11\"></a>Hadoop集群2022.11.11</h1><ul>\n<li><p><a href=\"#_2\">一、知识点回顾</a></p>\n</li>\n<li><p><a href=\"#_5\">二、启动集群并测试</a></p>\n</li>\n<li><p><a href=\"#20221115_46\">2022.11.15</a></p>\n</li>\n<li><p><a href=\"#hadoop_47\">一、安装hadoop出现的问题</a></p>\n</li>\n<li><p><a href=\"#Hadoop_61\">二、Hadoop的生态系统</a></p>\n</li>\n<li><p><a href=\"#HDFS_85\">三、分布式文件系统HDFS</a></p>\n</li>\n<li><p><a href=\"#HDFS_179\">二、HDFS简介</a></p>\n</li>\n<li><p><a href=\"#HDFS_191\">三.HDFS相关概念</a></p>\n</li>\n<li><p><a href=\"#HDFS_215\">四.HDFS体系结构</a></p>\n</li>\n<li><p><a href=\"#HDFS_248\">五.HDFS存储原理</a></p>\n</li>\n<li><p><a href=\"#HDFS_266\">六.HDFS数据读写过程</a></p>\n</li>\n<li><p><a href=\"#HFS_278\">七.HFS编程</a></p>\n</li>\n<li><p><a href=\"#_298\"></a></p>\n</li>\n</ul>\n<h1 id=\"一、知识点回顾\"><a href=\"#一、知识点回顾\" class=\"headerlink\" title=\"一、知识点回顾\"></a>一、知识点回顾</h1><h1 id=\"二、启动集群并测试\"><a href=\"#二、启动集群并测试\" class=\"headerlink\" title=\"二、启动集群并测试\"></a>二、启动集群并测试</h1><p>先删除集群<br>rm -rf &#x2F;usr&#x2F;local&#x2F;hadoop-2.7.7&#x2F;tmp</p>\n<p>1、启动集群 start-all.sh<br>jps：查看HDFS相关的节点进程<br>2720 DataNode<br>2897 SecondaryNameNode<br>2578<br>3491 Jps<br>3352 NodeManager<br>3066 ResourceManager</p>\n<p>HDES相关的节点进程：主从结构，一主多从<br>NameNode：名称节点，HDFs的主节点，Master,负责HDFs分布式文件系统元数据的存储与处理<br>DataNode：数据节点，HDFS的从节点，通常有1到多个，负责存储数据<br>SecondaryNameNode：第二名称节点，辅助NameNode完成HDFS元数据的管理</p>\n<p>YARN相关的节点进程：主从结构，一主多从<br>ResourceManager：资源管理节点，YARN的主节点，负责整个集群资源的调度与管理<br>NodeManager：YARN的从节点，通常有1到多个，负责管理它所在节点的资源</p>\n<p>2、测试HDS<br>查看：<br>用命令 ：haddop fs：查看完整用法<br>（HDFS：分布式文件系统）<br>Web UI:URI地址，主机名或IP:端口号，默认端口50070<br>上传一个大数据文件进行测试<br>[bg@bgserver ~]$ hadoop fs -mkdir &#x2F;zhan<br>[bg@bgserver ~]$ hadoop fs -put VMware-workstation-full-16.0.0-16894299.exe &#x2F;zhan<br>[bg@bgserver ~]$ hadoop fs -ls &#x2F;zhan<br><img src=\"https://img-blog.csdnimg.cn/7078e85a16b440fc8fdb49b334e05efa.png\" alt=\"在这里插入图片描述\"><img src=\"https://img-blog.csdnimg.cn/01709f191dda463e8db1f0a5d23ede7d.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/5de9505c4ef44c27bd45fbfe1ce93a5e.png\" alt=\"在这里插入图片描述\"><br>3、测式YARN和MR<br>查看：web UI：URI地址，主机名或IP:端口号，默认端口8088<br><img src=\"https://img-blog.csdnimg.cn/2346da5984634112b211eb44e103d4b7.png\" alt=\"在这里插入图片描述\"><br>跑应用程序<br><img src=\"https://img-blog.csdnimg.cn/93ab2834174b4dab97ae1053d06c4b39.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/216a4ecc9a574eb8b4256b57e5875a1e.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/257411ca8d6a406f91574b8cf95c831d.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/b3fe64fd068d4001991fffe9b4c0cc47.png\" alt=\"在这里插入图片描述\"></p>\n<h1 id=\"2022-11-15\"><a href=\"#2022-11-15\" class=\"headerlink\" title=\"2022.11.15\"></a>2022.11.15</h1><h2 id=\"一、安装hadoop出现的问题\"><a href=\"#一、安装hadoop出现的问题\" class=\"headerlink\" title=\"一、安装hadoop出现的问题\"></a>一、安装hadoop出现的问题</h2><p>1、<br>命令未找到：HADOOP HOME环境变量设置<br>文件不存在：关注JDR的设置与路径<br>2、<br>少节点：查看节点日志文件<br>userlogs：日志文件<br>cat &#x2F;usr&#x2F;local&#x2F;hadoop<br>3、<br>INFO:信息<br>WARN：警告<br>ERROR：错误<br>FATAL：致命错误<br>4、排查：配置文件中结构问题、属性名称、属性值、路径对不对、相关资源权限</p>\n<h2 id=\"二、Hadoop的生态系统\"><a href=\"#二、Hadoop的生态系统\" class=\"headerlink\" title=\"二、Hadoop的生态系统\"></a>二、Hadoop的生态系统</h2><p>一、Hadoop生态系统相关组件<br>1、hdfs是Hadoop的分布式文件系统，存储，整个生态系统的基础<br>2、YARN，通用的资源管理器<br>3、MapReduce,并行计算框架，适用于批处理计算<br>4、HBase,基于Hadoop分布式数据库，列式数据库<br>5、Hive,基于Hadoop构建的数据仓库，数据存储在HDFS上，可将数据分析的任务写成的SQL查询转换成MapReduce程序进行执行<br>6、Spark，大数据内存计算框架，计算速度快<br>7、Zookeeper,分布式协调器，为集群运算提供分布式锁等机制<br>8、Sqoop，ETL工具，可以实现关系数据库与HDFS之间的数据迁移<br>9、Flume，日志收集工具<br>10、Storm，流计算框架<br><img src=\"https://img-blog.csdnimg.cn/f8dc161524fb499984ca5c51fdca2a28.png\" alt=\"在这里插入图片描述\"></p>\n<p>备注：<br>数据仓库和数据库的区别：<br>1、数据库存储的是原始数据，没经过任何加工；而数据仓库是为了满足数据分析需要设计的，对源数据进行了ETL（提取转换加载）过程，数据抽取工作分抽取、清洗、转换、装载；<br>2、数据仓库的数据量要比数据库大很多。</p>\n<p>OLTP 和OLAP区别<br>OLTP(Online transaction processing):在线&#x2F;联机事务处理。典型的OLTP类操作都比较简单，主要是对数据库中的数据进行增删改查，操作主体一般是产品的用户。<br>OLAP(Online analytical processing):指联机分析处理。通过分析数据库中的数据来得出一些结论性的东西<br><img src=\"https://img-blog.csdnimg.cn/21f414da83f147e6a31f84eb80c9c938.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"三、分布式文件系统HDFS\"><a href=\"#三、分布式文件系统HDFS\" class=\"headerlink\" title=\"三、分布式文件系统HDFS\"></a>三、分布式文件系统HDFS</h2><p>一、分布式文件系统<br>1·分布式文件系统部署由多个节点构成的计算机集群上。<br>2.分布式文件系统中的节点通常分类两类：一类称主节点，也称Namenode(名称节点)，用于存储和管理文件系统的元数据；另一类是从节点，也称Datanode(数据节点)，负责存储数据，响应客户瑞的数据读写请求，在主节点的调度下实现数据复制与备份。<br><img src=\"https://img-blog.csdnimg.cn/15b58e9899204de9a4b92d584cd86358.png\" alt=\"在这里插入图片描述\"><br>客户端：shell，java API<br><img src=\"https://img-blog.csdnimg.cn/35bbe2cf01ee46e294cc5954f8d381b0.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/ed587bbbdb6e42e0832ee299e2b225cd.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/63a5ded94d3b47238e3091720c4ace63.png\" alt=\"在这里插入图片描述\"><br>连接拒绝<br><img src=\"https://img-blog.csdnimg.cn/b853c29671b944b2b2482490c2dda29f.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/c49cdf0704d44dbb852ee6fa88ce0de4.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/1a7777794f3f4303be8eb5c8bf4eac65.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/3425e0c323c54f34b99ad543b1a9a6d3.png\" alt=\"在这里插入图片描述\"><br>二、HDFS实现的目标<br>优点：<br><img src=\"https://img-blog.csdnimg.cn/dffa2c87a8464f5881cfaf988a22d732.png\" alt=\"在这里插入图片描述\"><br>不足：<br><img src=\"https://img-blog.csdnimg.cn/61fbf3896ae7437da0b378be4d923951.png\" alt=\"在这里插入图片描述\"><br>（3）不支持多用户写入，随机写<br>文件的修改； 不适合多次写入，一次读取（少量读取）<br>4、不支持多用户的并行写。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/ae26bb5ae3f940968f0458f67031a3eb.png\" alt=\"在这里插入图片描述\"><br>2022.11.18<br>实训<br>1.启动hadoop， 通过jps命令查看启动进程，通过web方式查看namenode和jobtracker，localhost:50070（将查看结果截图放入下方）<br>答：<br>启动hadoop：start-all.sh<br>查看进程:jps<br>namenode是HDES Web UI<br>jobtracker是YARN Web UI<br>HDES Web UI:主机名或IP:50070<br>YARN Web UI:主机名或IP:18088<br><img src=\"https://img-blog.csdnimg.cn/57af5890fe864ab298a493b3a8c8a73f.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/72718c9addd74e61ab5a51fad6aafeaf.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/01bd649c8d864b68b5ea52929ac4450d.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/ebf89a63dc1245b2b0417352d3ef8114.png\" alt=\"在这里插入图片描述\"><br>小贴士：<br>hadoop fs -ls &#x2F;<br>hdfs dfs -ls &#x2F;<br><img src=\"https://img-blog.csdnimg.cn/f6d2c6fe3d114dd59f560cd66291716e.png\" alt=\"在这里插入图片描述\"><br>考试必考<br><img src=\"https://img-blog.csdnimg.cn/91ad2f819aae402498d1bfdab5dcfc0e.png\" alt=\"在这里插入图片描述\"><br>1.[-cat[-ignoreCrc]】查看<br>cp [-f][-p I-p[topax]]…]复杂<br>[-get [-p][-ignoreCrc][-crc]…]<br>【-help[cmd …]帮助<br>[-mkdir[-p]】创建<br>[-mv.】移动<br>[-put[[p][】.】上传<br>错误原因：磁盘错误<br>安全模式：<br>一般是off<br><img src=\"https://img-blog.csdnimg.cn/e75c9858cba94045a09bedba1de4ba28.png\" alt=\"在这里插入图片描述\"><br>查看安全模式<br><img src=\"https://img-blog.csdnimg.cn/7e4ec7217d52472997fb213f27067164.jpeg\" alt=\"在这里插入图片描述\"><br>查看日志：<br><img src=\"https://img-blog.csdnimg.cn/a14c3cdf1aa44b25ab9cd169d77ad165.jpeg\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/fc74ea3100b743238a42c6b45596df36.jpeg\" alt=\"在这里插入图片描述\"></p>\n<ol start=\"2\">\n<li>在hdfs根目录下创建tmp目录，通过ls命令查看hadoop下tmp目录中的文件<br>答：<br><img src=\"https://img-blog.csdnimg.cn/90784f1c39ac4e988239e809cb72af96.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/1991b7dd560445998985c8a2ca0aeef3.png\" alt=\"在这里插入图片描述\"><br>3.进入hadoop目录，执行命令：hadoop fs -ls &#x2F; 列出HDFS上的文件<br>答：<br>cd $HADOOP_HOME</li>\n</ol>\n<p><img src=\"https://img-blog.csdnimg.cn/62655121a31342ecbda789b0260c53a7.png\" alt=\"在这里插入图片描述\"><br>4. 在HDFS上 &#x2F;user下创建一个你自己拼音名字的目录<br><img src=\"https://img-blog.csdnimg.cn/a2db11e682884120a04a1acd6a4c3b45.png\" alt=\"在这里插入图片描述\"><br>5. 退出hadoop目录，回到用户主目录，创建一个test目录，进入test目录，执行echo “hello world” &gt;test1.txt 命令创建test1.txt文件，并输入hello world内容。<br>&gt;:重定向符</p>\n<p><img src=\"https://img-blog.csdnimg.cn/fdfef2e5e52e49969010ca12bc5bef02.png\" alt=\"在这里插入图片描述\"></p>\n<p>6.继续回到hadoop目录下，将刚才在本地创建的test1.txt上传（put）到HDFS下你名字的目录下。<br><img src=\"https://img-blog.csdnimg.cn/8147fbb963754be79486e7115d665273.png\" alt=\"在这里插入图片描述\"><br>7. 查看HDFS下刚才上传的文件的内容<br><img src=\"https://img-blog.csdnimg.cn/f15a5e6d16d44233bc58e21ccd93df71.png\" alt=\"在这里插入图片描述\"><br>8.退出hadoop目录，回到用户主目录，彻底删除test目录。<br>cd<br>rm -rf test<br>ll<br><img src=\"https://img-blog.csdnimg.cn/baf42752122748df9e7ee5af6902438d.png\" alt=\"在这里插入图片描述\"><br>9.回到hadoop目录下，将HDFS上的test1.txt文件下载到用户主目录并查看<br><img src=\"https://img-blog.csdnimg.cn/327e5a169fa5495d9b6afab036108f3c.png\" alt=\"在这里插入图片描述\"><br>hadoop fs -get &#x2F;user&#x2F;zhangsan&#x2F;test1.txt 这个是回到当前目录<br>hadoop fs -get &#x2F;user&#x2F;hanyang&#x2F;test1.txt &#x2F;home&#x2F;bg 回到主目录<br><img src=\"https://img-blog.csdnimg.cn/cae94d7813fd4954b3a03d8c59771a23.png\" alt=\"在这里插入图片描述\"><br>10.在HDFS上删除test1.txt文件。<br><img src=\"https://img-blog.csdnimg.cn/e215a568458547749645709cceec1187.png\" alt=\"在这里插入图片描述\"></p>\n<h1 id=\"二、HDFS简介\"><a href=\"#二、HDFS简介\" class=\"headerlink\" title=\"二、HDFS简介\"></a>二、HDFS简介</h1><p>1.HDFS是谷歌GFS分布式文件系统的开源实现，Hadoop:生态系统分布式文件系统。<br>2.HDFS的实现目标：（优点）<br>a、兼容廉价的计算机硬件<br>b、流数据读写<br>c、简单的数据访问模型（一次写入，多次读取）<br>d、处理大数据集，文件数据量级在GB到TB级<br>3.HDFS的局限性（不足）<br>a、不适合低延迟数据访问<br>b、无法高效存储大量小文件<br>c、不支特多用户写和随机写</p>\n<h1 id=\"三-HDFS相关概念\"><a href=\"#三-HDFS相关概念\" class=\"headerlink\" title=\"三.HDFS相关概念\"></a>三.HDFS相关概念</h1><p>1.块<br>（1）HDFS采用文件分块冗余存储的机制，来解决大数据的数据存储与可用性<br>（2）HDFS块通常要普通文件系统的块大很多<br>（3）问答题 分块存储策略带来的好处：支持大规模文件存储、简化系统设计、适合数据备份<br>（4）HDFS与其他分布式文件显著的区别在于：启用机架感知机制<br>2.名称节点<br>（1）名称节点是HDFS的主节点，存诸HDFS文件系统的元数据<br>（2）两个重要数据结构：FsImage和Editlog<br>FsImage存放某个时间点上，HDFS文件系统元数据快照<br>Editlog存储是对HDFS 文件系统的更新操作<br>3.第二名称节点SecondaryNameNode，<strong>辅助节点</strong></p>\n<p>随着时间推移，Editlog会不断变大。HDFS会定期检查Editlog，让SecondaryNameNode启动复制合并机制：SecondaryNameNode会将FsImage和Editlog从NameNode所在节点拉取到自己所在的节点（之后的HDFS更新操作会写入一个新的Editlog文件)，对FsImage和Editlog文件进行合并，得到新的FsImage,再将新FsImage送回Namenode所在节点。</p>\n<p>如果Namenode挂掉，存在的元数据丢失，如何恢复集群，SecondaryNameNode有一个FsImage备份（冷备份）<br>SecondaryNameNode能起到冷备份作用。</p>\n<p>4.数据节点<br>（1）数据节点，是HDFS的从节点，通常有多个<br>（2）数据节点负责存放数据，负责响应客户端数据的读写请求<br>（3）数据节点会定期向名称节点报告自己的信息（心跳信息），说明自己是否可用、数据块列表等<br>datanode通过心跳信息告诉namenode自己还在后，namenode才调度读写任务给datanode</p>\n<h1 id=\"四-HDFS体系结构\"><a href=\"#四-HDFS体系结构\" class=\"headerlink\" title=\"四.HDFS体系结构\"></a>四.HDFS体系结构</h1><p>1、概述<br>（1）HDFS采用了主从(Master&#x2F;Slave)结构模型，一个HDFS集群包括一个名称节点(NameNode)和若干个数据节点(DataNode)。<br>默认块大小 dfs.blocksize 默认 128MB<br>默认块副本数 dfs.replication 默认为3</p>\n<p>（2）名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。<br>（3）集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读&#x2F;写请求，在名称节点的统<br>一调度下进行数据块的创建、删除和复制等操作。<br>（4）每个数据节点的数据实际上是保存在本地Linux文件系统中的。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/db2cf45a887944bb8aae03b5251051a0.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/569b715dd7c44de28bee8564f479ecfc.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/a1e7b8cc34fd40f9a98cdeeab9c5abc3.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/dc2efe263a444876bbb5d2d95e6f2857.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/9858102c5b9a4ae4a8c3f4754d650367.png\" alt=\"在这里插入图片描述\"></p>\n<p>2、HDFS命名空间<br>（1）HDFS命名空间：独立、唯一<br>（2）HDFS命名空间面向所有应用、项目，相互没有隔离<br>3、通信协议<br>（1）HDFS采用 TCP&#x2F;IP协议<br>（2）客户端与集群之间、集群内部各节点之间，都是通过RPC （远程过程调用）进行通信<br>4、客户端<br>（1）HDFS shell 命令： -ls -mkdir -cat -put -get -rm -mv<br>（2）HDFS Java API</p>\n<p>5、HDFS不足<br>（1）命名空间限制<br>（2）性能的瓶颈：单点（NameNode）<br>（3）隔离问题<br>（4）集群可用性，单点故障（SPOF），生产环境可采用Hadoop HA（高可用）、Hadoop联邦机制</p>\n<h1 id=\"五-HDFS存储原理\"><a href=\"#五-HDFS存储原理\" class=\"headerlink\" title=\"五.HDFS存储原理\"></a>五.HDFS存储原理</h1><p>1、数据的冗余存储<br>（1）HDFS采用多副本冗余存储策略，默认存储3份，<br>（2）多副本存储带来的好处：加快数据传输速度、容易检查数据错误、保证数据的可用性<br>2、数据存取策略<br>1.数据存放策略<br>（1）第1副本：如果是集群内提交，则直接存在本地节点；如果集群外提交，则选择磁盘不太满、CPU不太忙的节点进行存储<br>第2个副本：选择与第1个副本不同机架上的节点进行存储，目的是安全（防止交换机出问题）<br>第3个副本：选择与第1个副本相同机架上的节点进行存储，目的是数据的高效和可用<br>如果有更多副本，则随机选择节点进行存储</p>\n<p>2.数据读取策略<br>HDFS提供API可用确定数据所在机架 ID，客户端可以调用API来确定自己的机架ID，采用就近原则来读取数据。如果没有，则随机选择一块。</p>\n<p>3、数据错误与恢复<br>（1）名称节点出错：可采用SecondaryNamenode中的冷备份进行恢复<br>（2）数据节点出错：名称节点若没有收到数据节点心跳信息，可将该数据节点标记不可用。若因为数据节点不可用造成文件数据块副本数低于副本数要求，则启动复制机制复制文件块，使副本数达到要求。<br>（3）数据出错：HDFS在存储数据时，会计算校验码，存放在数据块文件相同的路径下，读取时会通过校验码对数据进行校验。</p>\n<h1 id=\"六-HDFS数据读写过程\"><a href=\"#六-HDFS数据读写过程\" class=\"headerlink\" title=\"六.HDFS数据读写过程\"></a>六.HDFS数据读写过程</h1><p>1.写数据的过程<br>（1）建立FileSystem对象<br>（2）创建文件：FileSystem对象create方法，返回FSDataOutputStream对象<br>（3）使用FSDataOutputStream对象的write方法写入用户数据<br>（4）关闭对象将数据存放HDFS文件系统<br>2.读数据的过程<br>（1）建立FileSystem对象<br>（2）打开文件：FileSystem对象open方法，返回FSDataInputStream对象<br>（3）FSDataInputStream对象read方法（借助BufferedReader的readline）来实现数据读取<br>（4）关闭对象</p>\n<h1 id=\"七-HFS编程\"><a href=\"#七-HFS编程\" class=\"headerlink\" title=\"七.HFS编程\"></a>七.HFS编程</h1><p>1.HDFS shell<br>hadoop fs<br>hdfs dfs</p>\n<p>2.HDFS-Java API:(导包方式、Maven）<br>（1)准备开发环境：JDK+IDEA<br>（2)准备Hadoop程序包：<br>$HADOOP HOME&#x2F;share&#x2F;hadoop目录common、hdfs、mapreduce、yarn四个子目录下所有.jar文件<br><img src=\"https://img-blog.csdnimg.cn/60ba60ef73ef4516b3d0145c10a28d5a.png\" alt=\"在这里插入图片描述\"><br>3、启动IDEA，建立Java空项目<br>4)在项目引入Hadoop程序包：File–&gt;Project Structure–&gt;Libraries–&gt;±-&gt;Java–&gt;找到jar所在目录<br>5)新建Java类，编写程序<br>Configuration : core-default.xml core-site.xml<br>fs.defaultFS RPC<br>6)定义包：File-&gt;Project Structure-&gt;Artifacts-&gt;±&gt;JAR-&gt;选择带依赖打包-&gt;定义main class</p>\n<p>7)生成JAR包：Build–&gt;Build Artifacts–&gt;build<br><img src=\"https://img-blog.csdnimg.cn/c96ed67f2bd34877838d65f3ad91f954.png\" alt=\"在这里插入图片描述\"><br>2022.11.25</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>请编写程序，实现如下逻辑：（程序与运行结果均以截图形式提交）</p>\n<p>1）从命令行参数读入文件名file1</p>\n<ol start=\"2\">\n<li>访问HDFS，判断file1是否存在，若存在则输出“文件已存在”，程序结束</li>\n</ol>\n<p>3）若file1不存在，则在HDFS上创建该文件，并写入如下两行信息，其中班级、学号、姓名使用自己的个人信息</p>\n<pre class=\"line-numbers language-auto\" data-language=\"auto\"><code class=\"language-auto\">软件工程xxx班学生名单\n\n123456789,张三</code></pre>\n\n<p>4）成功写入后，程序输出如下提示信息：</p>\n<p>HDFS数据写入成功！写入内容如下：</p>\n<pre class=\"line-numbers language-auto\" data-language=\"auto\"><code class=\"language-auto\">软件工程xxx班学生名单\n\n123456789,张三</code></pre>\n\n<p>5）在程序中读从HDFS中读取file1文件内容，并对文件内容进行解析，并参考如下格式输出信息:</p>\n<p>大家好！我是张三，我的学号:123456789，我来自软件工程xxx班。</p>\n<p>程序整体输出参考下图：<br><img src=\"https://img-blog.csdnimg.cn/58f7281b3b274dd7b18d87cc16816dec.png\" alt=\"在这里插入图片描述\">作业逻辑<br>1、读命令行参数<br>2、访问HDFS,判断file1是否存在<br>3、在HDFS上创建该文件，写入数据<br>（写入如下两行信息，其中班级、学号、姓名使用自己的个人信息）<br>4、读HDFS文件内容</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2ebc38406fb049b5b3e24daeb761424d.png\" alt=\"在这里插入图片描述\">调用hadoop，fs -ls &#x2F; 命令行参数</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">&#x2F;*\n1、读命令行参数\n2、访问HDFS,判断file1是否存在\n3、在HDFS上创建该文件，写入数据\n（写入如下两行信息，其中班级、学号、姓名使用自己的个人信息）\n4、读HDFS文件内容\n *&#x2F;\npackage cn.edu.ahdy.bg;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FSDataOutputStream;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\n\nimport java.io.IOException;\n\npublic class ex01 &#123;\n    public static void main(String[] args) throws IOException &#123;\n                           &#x2F;&#x2F;hadoop fs -ls &#x2F;\n                                  &#x2F;&#x2F;fs对应args[0] ls对应args[1] &#x2F;对应args[2]\n        &#x2F;&#x2F;访问HDFS\n        &#x2F;&#x2F;1.创建Configuration对象\n        Configuration conf &#x3D; new Configuration();\n        Path file1 &#x3D; new Path(args[0]);\n\n\n        &#x2F;&#x2F;2.获取FileSystem对象\n        FileSystem fs&#x3D; FileSystem.get(conf);\n\n        &#x2F;&#x2F;3.创建文件\n        FSDataOutputStream out &#x3D; fs.create(file1);\n\n        &#x2F;&#x2F;4.写数据\n       String str&#x3D;&quot;软件工程212,1234546789，张三&quot;;\n       out.write(str.getBytes());\n\n\n       &#x2F;&#x2F;5.写完数据关闭对象，释放资源\n        out.close();\n        fs.close();\n\n\n    &#125;\n&#125;\n</code></pre>\n\n<p><img src=\"https://img-blog.csdnimg.cn/103b10b2a37d4a648579567d89c0baa4.png\" alt=\"在这里插入图片描述\"><img src=\"https://img-blog.csdnimg.cn/dd12759831204bdf9cb25b817bb24fbd.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/0b79d4d9c0e9401184716abfac7fd3af.png\" alt=\"在这里插入图片描述\"><img src=\"https://img-blog.csdnimg.cn/6370993b73be4dcb9efb847b861f1d05.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/821208b5e0ee4eadbd232fd05b60d643.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/c80c4bff514a455096dbca80f8e250d9.png\" alt=\"在这里插入图片描述\">找到jar并导入jar<br><img src=\"https://img-blog.csdnimg.cn/4e04fa3189c44e8dbf92a794393a560d.png\" alt=\"在这里插入图片描述\">查看jps，并启动集群<br><img src=\"https://img-blog.csdnimg.cn/ce51c48ba6a3449d8826825e91728b30.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/04c0b3bc6988471eab4fb58f153d0de2.png\" alt=\"在这里插入图片描述\"></p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">&#x2F;*\n1、读命令行参数\n2、访问HDFS,判断file1是否存在\n3、在HDFS上创建该文件，写入数据\n（写入如下两行信息，其中班级、学号、姓名使用自己的个人信息）\n4、读HDFS文件内容\n *&#x2F;\npackage cn.edu.ahdy.bg;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FSDataInputStream;\nimport org.apache.hadoop.fs.FSDataOutputStream;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\n\nimport java.io.BufferedReader;\nimport java.io.FilterInputStream;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\n\npublic class ex01 &#123;\n    public static void main(String[] args) throws IOException &#123;\n                           &#x2F;&#x2F;hadoop fs -ls &#x2F;\n                                  &#x2F;&#x2F;fs对应args[0] ls对应args[1] &#x2F;对应args[2]\n        &#x2F;&#x2F;访问HDFS\n        &#x2F;&#x2F;1.创建Configuration对象\n        Configuration conf &#x3D; new Configuration();\n        Path file1 &#x3D; new Path(args[0]);\n\n\n        &#x2F;&#x2F;2.获取FileSystem对象\n        FileSystem fs&#x3D; FileSystem.get(conf);\n\n        &#x2F;&#x2F;3.创建文件\n        FSDataOutputStream out &#x3D; fs.create(file1);\n\n        &#x2F;&#x2F;4.写数据\n       String str&#x3D;&quot;软件工程212,1234546789，张三&quot;;\n       out.write(str.getBytes());\n\n\n       &#x2F;&#x2F;5.写完数据关闭对象，释放资源\n        out.close();\n\n        &#x2F;&#x2F;读数据\n        &#x2F;&#x2F;1.打开文件\n        FSDataInputStream in &#x3D; fs.open(file1);\n        &#x2F;&#x2F;2.\n        BufferedReader reader&#x3D; new BufferedReader(new InputStreamReader(in));\n\n        String temp &#x3D;reader.readLine();\n        String[] infos &#x3D; temp.split(&quot;,&quot;);\n        System.out.printf(&quot;大家好！我是%s，我的学号:%s，我来自%s班&quot;,infos[2],infos[1],infos[0]);\n\n        reader.close();\n        in.close();\n        fs.close();\n\n    &#125;\n&#125;\n</code></pre>\n\n<p>不指定类<img src=\"https://img-blog.csdnimg.cn/79107da416cc4617b0e0b45ad2e1d7bd.png\" alt=\"在这里插入图片描述\"><br>类不存在<br><img src=\"https://img-blog.csdnimg.cn/9222e89fa8244ed1aec137f0ca615d78.png\" alt=\"在这里插入图片描述\">解决方法<br>1.</p>\n<p><img src=\"https://img-blog.csdnimg.cn/df6df418d6044b489eba903193c2671b.png\" alt=\"在这里插入图片描述\">2.<br><img src=\"https://img-blog.csdnimg.cn/1a4e055b8e9148dea64956884d54097c.png\" alt=\"在这里插入图片描述\"></p>\n","text":"Hadoop集群2022.11.11 一、知识点回顾 二、启动集群并测试 2022.11.15 一、安装hadoop出现的问题 二、Hadoop的生态系统 三、分布式文件系统HDFS 二、HDFS简介 三.HDFS相关概念 四.HDFS体系结构 五.HDFS存储原理 六.HDFS...","link":"","photos":[],"count_time":{"symbolsCount":"9.3k","symbolsTime":"8 mins."},"categories":[{"name":"考试","slug":"考试","count":4,"path":"api/categories/考试.json"}],"tags":[{"name":"考试","slug":"考试","count":4,"path":"api/tags/考试.json"},{"name":"Hadoop","slug":"Hadoop","count":1,"path":"api/tags/Hadoop.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hadoop%E9%9B%86%E7%BE%A42022-11-11\"><span class=\"toc-text\">Hadoop集群2022.11.11</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE\"><span class=\"toc-text\">一、知识点回顾</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4%E5%B9%B6%E6%B5%8B%E8%AF%95\"><span class=\"toc-text\">二、启动集群并测试</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#2022-11-15\"><span class=\"toc-text\">2022.11.15</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81%E5%AE%89%E8%A3%85hadoop%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">一、安装hadoop出现的问题</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81Hadoop%E7%9A%84%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">二、Hadoop的生态系统</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%89%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS\"><span class=\"toc-text\">三、分布式文件系统HDFS</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81HDFS%E7%AE%80%E4%BB%8B\"><span class=\"toc-text\">二、HDFS简介</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%89-HDFS%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">三.HDFS相关概念</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9B%9B-HDFS%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">四.HDFS体系结构</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%94-HDFS%E5%AD%98%E5%82%A8%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">五.HDFS存储原理</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%85%AD-HDFS%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B\"><span class=\"toc-text\">六.HDFS数据读写过程</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%83-HFS%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">七.HFS编程</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\"><span class=\"toc-text\"></span></a></li></ol>","author":{"name":"FangH","slug":"blog-author","avatar":"/img/fh.png","link":"/","description":"我曾惊鸿一瞥未来","socials":{"github":"https://github.com/FHangH","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/zi-heng-18-99-47","csdn":"https://blog.csdn.net/weixin_44519692?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Linux考试","uid":"2a4416dfe7e87d0be836e5eac76b7a8f","slug":"temp_Linux","date":"2022-12-04T05:07:37.200Z","updated":"2023-01-10T01:10:19.437Z","comments":true,"path":"api/articles/temp_Linux.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/FHangH/FHangBlogCDN_03@master/Aurora_ (108).webp","text":"Linux1.0一、填空题1．GNU的含义是GNU’s Not Unix的递归缩写。 2．Linux一般有3个主要部分：内核（kernel）、命令解释层（Shell或其他操作环境）、实用工具。 3．**”&#x2F;etc&#x2F;sysconfig&#x2F;network”...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"10 mins."},"categories":[{"name":"考试","slug":"考试","count":4,"path":"api/categories/考试.json"}],"tags":[{"name":"Linux","slug":"Linux","count":1,"path":"api/tags/Linux.json"},{"name":"考试","slug":"考试","count":4,"path":"api/tags/考试.json"}],"author":{"name":"FangH","slug":"blog-author","avatar":"/img/fh.png","link":"/","description":"我曾惊鸿一瞥未来","socials":{"github":"https://github.com/FHangH","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/zi-heng-18-99-47","csdn":"https://blog.csdn.net/weixin_44519692?spm=1000.2115.3001.5343","juejin":"","customs":{}}}},"next_post":{"title":"MultiPlayer-RPG-OpenLevel","uid":"29a6d737f8291ebb946b1c03a0d2e8fa","slug":"998_代号-OP_01","date":"2022-11-12T02:47:09.905Z","updated":"2023-01-10T01:10:19.437Z","comments":true,"path":"api/articles/998_代号-OP_01.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/FHangH/FHangBlogCDN_03@master/Aurora_ (32).webp","text":"MultiPlayer-RPG-OpenLevel 游戏介绍 游戏名：代号-OP 开发人：Fangh 项目启动时间：2022-11-12 | 09:30 项目完成时间：**** 项目日志 2022-11-12 | 09:30：项目开始 2022-11-17 | 9:00：开始设计...","link":"","photos":[],"count_time":{"symbolsCount":"4k","symbolsTime":"4 mins."},"categories":[{"name":"UnrealEngine","slug":"UnrealEngine","count":12,"path":"api/categories/UnrealEngine.json"},{"name":"Demo","slug":"UnrealEngine/Demo","count":1,"path":"api/categories/UnrealEngine/Demo.json"}],"tags":[{"name":"UnrealEngine","slug":"UnrealEngine","count":12,"path":"api/tags/UnrealEngine.json"},{"name":"Demo","slug":"Demo","count":1,"path":"api/tags/Demo.json"}],"author":{"name":"FangH","slug":"blog-author","avatar":"/img/fh.png","link":"/","description":"我曾惊鸿一瞥未来","socials":{"github":"https://github.com/FHangH","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/zi-heng-18-99-47","csdn":"https://blog.csdn.net/weixin_44519692?spm=1000.2115.3001.5343","juejin":"","customs":{}}}}}